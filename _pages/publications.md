---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---
 coming soon ...
<!--<html>
    <table style="width:120%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:20%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
              <img src="../images/MASTAR.jpg" alt="hpp" style="border-style: none" >
            </td>
            <td style="padding:40px;width:80%;font-size: 1.30em;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <papertitle>MASSTAR: A Multi-Modal Large-Scale Scene Dataset with a Versatile Toolchain for Surface Prediction and Completion
                </papertitle>
              <br>
                Jinqi Jiang* , <strong>Guiyong Zheng*</strong>, Chen Feng*, Shaojie Shen, and Boyu Zhou
              <br>
              <em><strong>[Under Review]</strong>  Submitted to Proc. of the IEEE International Conference on Robotics and Automation <strong>(ICRA)</strong>,2024. Yokohama, Japan..</em><br>
              <!-- <a href="https://ieeexplore.ieee.org/document/10243098">Paper</a> /
              <a href="https://arxiv.org/abs/2306.03207">Arxiv</a> / -->
              <a href="https://github.com/SYSU-STAR/MASSTAR">Code</a> /
              <!-- <a href="https://youtu.be/oR9MlfL86Vw">Video (Youtube)</a> / -->
              <a href="https://www.bilibili.com/video/BV1fy4y1F7Z6/?spm_id_from=333.999.0.0&vd_source=7d9ba13550e9ec24b6bf69d5c3ff3">Video (Bilibili)</a>
            </td>
          </tr>
    </table>
</html> -->

<!-- <hr>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=W25Fdb-NQUH1UObkKuunx_1va-9MG_ZujLrO3eIij5c'></script> -->
